# coding: utf-8
import nltk
from helper import Alphabet, Instance
from naive_bayes import NaiveBayes
import util
from evaluator import split_train_test

filelist1 = get_ipython().getoutput(u'ls txt_sentoken/neg/')
filelist2 = get_ipython().getoutput(u'ls txt_sentoken/pos/')
ins_list = []

nb = NaiveBayes()

#here we extract the feature from .txt files and we assume that the training process uses the 
#raw_data of instance to train while the testing precess using the data of instance to test. But for #convenience of using the test_naive_bayes.py, I populate the data and raw_data of instance at the #same time
    
for filename in filelist1:
	f = open('txt_sentoken/neg/'+filename,'r')
	tokens=[]
	data=[]
	#read each line
	for l in f:
		tokens += nltk.regexp_tokenize(l,pattern="\w+")
	data = util.del_dup(tokens)
	ins = Instance(filename,'negative',data,tokens)	
	ins_list.append(ins)
		
for filename in filelist2:
	f = open('txt_sentoken/pos/'+filename,'r')
	tokens=[]
	data=[]
	for l in f:
		tokens += nltk.regexp_tokenize(l,pattern="\w+")
	data = util.del_dup(tokens)
	ins = Instance(filename,'positive',data,tokens)	
	ins_list.append(ins)

prp = [0.5,0.5]
pp = split_train_test(nb,ins_list,prp)
   

    
